# ğŸ™ï¸ Dexter AI â€” Streaming Voice Agent

![Dexter AI Banner](https://img.shields.io/badge/Voice-Agent-Streaming-blue?style=for-the-badge) ![FastAPI](https://img.shields.io/badge/FastAPI-ğŸš€-green?style=for-the-badge) ![WebSockets](https://img.shields.io/badge/WebSockets-Live-orange?style=for-the-badge)

**Dexter AI** is a persona-driven, real-time **streaming voice agent** ğŸ—£ï¸. It listens to your microphone, understands you through **speech-to-text (STT)**, reasons with an **LLM**, and replies with **text-to-speech (TTS)** â€” all in real time âš¡. Default persona: *Dexter Morgan* ğŸ©¸ (yes, that Dexter ğŸ˜).

Itâ€™s built on **FastAPI** with a clean, modular service design. Beyond conversations, it can fetch you **latest news** ğŸ“°, **weather updates** ğŸŒ¦ï¸, and handle **file uploads & transcriptions** ğŸ§.

---

## ğŸ“‘ Table of Contents
- [âœ¨ Project Summary](#-project-summary)
- [ğŸ”‘ Key Functionalities](#-key-functionalities)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸ› ï¸ Technologies](#ï¸-technologies)
- [âš™ï¸ Features & Endpoints](#ï¸-features--endpoints)
- [âš¡ Running Locally](#-running-locally)
- [ğŸš€ Future Improvements](#-future-improvements)

---

## âœ¨ Project Summary
Dexter AI demonstrates a modern streaming assistant pipeline:
1. **Browser Client** â†’ captures mic ğŸ¤ â†’ streams audio to server via **WebSocket**.
2. **Server (FastAPI)** â†’ orchestrates:
   - ğŸ”Š **AssemblyAI** â†’ transcribes speech â†’ text.
   - ğŸ§  **Google GenAI** â†’ generates context-aware responses.
   - ğŸ¶ **Murf TTS** â†’ speaks back with lifelike voice.
   - ğŸ“¡ **News & Weather APIs** â†’ supplement responses.
3. **Client Playback** â†’ streams back transcript & audio â†’ plays response.

---

## ğŸ”‘ Key Functionalities
âœ… **Real-time speech streaming** via WebSocket  
âœ… **AssemblyAI STT** for instant transcription  
âœ… **LLM-powered responses** using Google GenAI  
âœ… **Murf TTS** for natural voice replies  
âœ… **NewsAPI** ğŸ“° & **WeatherAPI** ğŸŒ¦ï¸ integrations  
âœ… **Session-based API keys & personas** ğŸ­  
âœ… **File uploads & offline transcription** ğŸ§  
âœ… **Browser client UI** with microphone capture & playback  

---

## ğŸ—ï¸ Architecture

### Detailed Flow
```mermaid
graph TD;
    subgraph Browser Client ğŸŒ
        A1[ğŸ¤ Microphone Input]
        A2[ğŸ“¦ Audio Chunks Encoding]
        A3[ğŸ”Œ WebSocket Connection]
        A1 --> A2 --> A3
    end

    subgraph FastAPI Server ğŸš€
        B1[ğŸŒ WS Handler /ws/stream]
        B2[ğŸ“¡ Session Manager (state.py)]
        B3[ğŸ“ STT Service - AssemblyAI]
        B4[ğŸ§  LLM Service - Google GenAI]
        B5[ğŸ¶ TTS Service - Murf]
        B6[ğŸ“° News Service - NewsAPI]
        B7[ğŸŒ¦ï¸ Weather Service - WeatherAPI]
        B8[ğŸ“œ History & Persona Manager]

        B1 --> B2
        B1 --> B3
        B3 -->|Transcript| B4
        B4 -->|Response Text| B5
        B4 --> B6
        B4 --> B7
        B2 --> B8
    end

    subgraph External Services â˜ï¸
        C1[AssemblyAI STT API]
        C2[Google GenAI API]
        C3[Murf TTS API]
        C4[NewsAPI]
        C5[WeatherAPI]
    end

    subgraph Browser Playback ğŸ§
        D1[ğŸ“ Live Transcript Display]
        D2[ğŸ”Š Audio Playback]
    end

    A3 --> B1
    B3 --> C1
    B4 --> C2
    B5 --> C3
    B6 --> C4
    B7 --> C5
    B5 --> D2
    B4 --> D1
```

---

## ğŸ› ï¸ Technologies
- **Backend:** FastAPI, Uvicorn, AsyncIO, WebSockets
- **LLM:** Google Generative AI (Gemini)
- **STT:** AssemblyAI
- **TTS:** Murf
- **Integrations:** NewsAPI, WeatherAPI
- **Client:** HTML + JS (WebSocket streaming, mic capture)
- **Infra Tools:** dotenv, aiohttp/httpx

---

## âš™ï¸ Features & Endpoints

### ğŸŒ WebSocket
- `ws://<host>/ws/stream` â†’ real-time pipeline (mic â†’ STT â†’ LLM â†’ TTS).

### ğŸ“¡ REST Endpoints
- `/upload` â†’ upload audio file
- `/transcribe/file` â†’ offline transcription
- `/api/weather?city=London` â†’ fetch weather
- `/api/news?country=us` â†’ fetch news
- `/history/{session_id}` â†’ get chat history
- `/debug/*` â†’ debugging endpoints

---

## âš¡ Running Locally

### ğŸ”§ Setup
```bash
# 1ï¸âƒ£ Clone repo
 git clone <repo_url>
 cd Dexter-AI

# 2ï¸âƒ£ Create virtual env
 python -m venv venv
 source venv/bin/activate   # macOS/Linux
 venv\Scripts\activate      # Windows

# 3ï¸âƒ£ Install requirements
 pip install -r requirements.txt

# 4ï¸âƒ£ Setup env vars (.env)
 cp .env.example .env
 # Add your API keys (AssemblyAI, Murf, GenAI, News, Weather)

# 5ï¸âƒ£ Run server
 uvicorn main:app --reload --port 8000

# 6ï¸âƒ£ Open in browser
 http://localhost:8000/
```

ğŸ‰ Done! Speak into your mic and Dexter AI will answer back ğŸ—£ï¸ â†’ ğŸ§  â†’ ğŸ¶

---

## ğŸš€ Future Improvements
- ğŸ’¾ **Persistent storage** (Redis / DB) for session history
- ğŸ” **Secure API key management**
- ğŸ“ˆ **Scalability**: worker queues, rate limits
- ğŸ¨ **UI upgrades**: multiple voices, adjustable pitch/rate
- âœ… **CI/CD pipeline** & tests

---

## ğŸ“œ License
MIT License â€” free to use, modify & share ğŸš€